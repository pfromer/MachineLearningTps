{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.misc import comb\n",
    "from sklearn.model_selection import train_test_split , KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize\n",
    "import pdb\n",
    "from sklearn.metrics import roc_auc_score , make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import NuestroArbol as ourTree\n",
    "import random\n",
    "from scipy.stats import randint as sp_randint\n",
    "from time import time\n",
    "import collections\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importo datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comp = pd.read_csv('X_competencia.csv')\n",
    "X = pd.read_csv('X.csv')\n",
    "y = pd.read_csv('y.csv')\n",
    "X.drop(['index'],inplace=True, axis=1)\n",
    "y.drop(['index'], inplace=True,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#partimos los datos en desarrollo(87%) y holdout(13%). \n",
    "X_desarrollo , X_holout ,y_desarrollo, y_holdout = train_test_split(X, y['output'],\n",
    "                                                                    test_size=0.13,random_state=0,stratify=y['output'])\n",
    "\n",
    "#a = normalize(X_desarrollo, axis=0, copy=True, return_norm=False)\n",
    "#from IPython.core.debugger import Tracer; Tracer()() \n",
    "#X_desarrollo = pd.DataFrame(SelectKBest(chi2, k=180).fit_transform(np.abs(X_desarrollo), y_desarrollo))\n",
    "\n",
    "#pase los kfold aca arriba ya que se usan en varios lugares.\n",
    "#evaluar si esta bueno que siempre se usen los mismos folds\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "kfold.get_n_splits(X_desarrollo,y_desarrollo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primerTablaEjercicio2(treeClasifier):\n",
    "    \n",
    "    accuracy_train=[]\n",
    "    accuracy_valildation=[]\n",
    "    ROC_AUC_train=[]\n",
    "    ROC_AUC_validation=[]\n",
    "\n",
    "    #este for itera sobre los k folds en cada loop tego un set de datos y otro de validacion\n",
    "    for train, test  in kfold.split(X_desarrollo,y_desarrollo):\n",
    "        #print(\"TRAIN:\", train_index,'\\n', \"TEST:\", test_index,'\\n' )\n",
    "        X_train, X_val = X_desarrollo.iloc[train], X_desarrollo.iloc[test]\n",
    "        y_train, y_val = y_desarrollo.iloc[train], y_desarrollo.iloc[test]\n",
    "        #intancio el arbol que voy a entrenar en cada fold\n",
    "        tree = treeClasifier(max_depth=3, criterion=\"gini\")\n",
    "        \n",
    "        #from IPython.core.debugger import Tracer; Tracer()()\n",
    "\n",
    "        tree.fit(X_train, y_train.astype(int))\n",
    "        accuracy_train.append(tree.score(X=X_train, y=y_train))\n",
    "        accuracy_valildation.append(tree.score(X=X_val, y=y_val))\n",
    "        ROC_AUC_train.append(roc_auc_score(y_train,tree.predict(X_train)))\n",
    "        ROC_AUC_validation.append(roc_auc_score(y_val,tree.predict(X_val)))\n",
    "        \n",
    "    return pd.DataFrame({ 'Partición' : np.arange(1,6),'Accuracy (training)' :accuracy_train,\n",
    "                          'Accuracy (validación)' : accuracy_valildation,\n",
    "                          'ROC AUC (training)' : ROC_AUC_train,\n",
    "                          'ROC AUC (validación)' : ROC_AUC_validation})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla de precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partición</th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>ROC AUC (training)</th>\n",
       "      <th>ROC AUC (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.783862</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.785980</td>\n",
       "      <td>0.660417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.813218</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.752394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.830460</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.820954</td>\n",
       "      <td>0.588564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.841170</td>\n",
       "      <td>0.592287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.828080</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.823049</td>\n",
       "      <td>0.630933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Partición  Accuracy (training)  Accuracy (validación)  ROC AUC (training)  \\\n",
       "0          1             0.783862               0.659091            0.785980   \n",
       "1          2             0.813218               0.758621            0.801587   \n",
       "2          3             0.830460               0.597701            0.820954   \n",
       "3          4             0.844828               0.597701            0.841170   \n",
       "4          5             0.828080               0.639535            0.823049   \n",
       "\n",
       "   ROC AUC (validación)  \n",
       "0              0.660417  \n",
       "1              0.752394  \n",
       "2              0.588564  \n",
       "3              0.592287  \n",
       "4              0.630933  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(primerTablaEjercicio2(DecisionTreeClassifier))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arboles combinaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyForTrainingAndValidation(depth,criteria,treeClasifier):\n",
    "    acc_train=[]\n",
    "    acc_val=[]\n",
    "\n",
    "\n",
    "    #este for itera sobre los k folds en cada loop tego un set de training y otro de validacion\n",
    "    for train, test  in kfold.split(X_desarrollo,y_desarrollo):\n",
    "        #print(\"TRAIN:\", train_index,'\\n', \"TEST:\", test_index,'\\n' )\n",
    "        X_train, X_val = X_desarrollo.iloc[train], X_desarrollo.iloc[test]\n",
    "        y_train, y_val = y_desarrollo.iloc[train], y_desarrollo.iloc[test]\n",
    "        #intancio el arbol que voy a entrenar en cada fold\n",
    "        tree = treeClasifier(max_depth=depth, criterion=criteria)\n",
    "\n",
    "        tree.fit(X_train, y_train.astype(int))\n",
    "        acc_train.append(tree.score(X=X_train, y=y_train))\n",
    "        acc_val.append(tree.score(X=X_val, y=y_val))\n",
    "        \n",
    "    return {\"training\":np.mean(acc_train), \"validation\": np.mean(acc_val)}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segundaTablaEjercicio2(treeClasifier):\n",
    "\n",
    "    trainingResults=[]\n",
    "    validationResults=[]\n",
    "    evaluatedDepths=[]\n",
    "    evaluatedCriterias=[]\n",
    "    depthsDictionary={3:'3',5:'5',None:'Infinito'}\n",
    "    depths = [3,5,None]    \n",
    "    criterias =['gini','entropy']\n",
    "\n",
    "    for depth in depths:\n",
    "        for criteria in criterias:\n",
    "            trainingResults.append(accuracyForTrainingAndValidation(depth,criteria,treeClasifier)[\"training\"])\n",
    "            validationResults.append(accuracyForTrainingAndValidation(depth,criteria,treeClasifier)[\"validation\"])\n",
    "            evaluatedDepths.append(depthsDictionary[depth])\n",
    "            evaluatedCriterias.append(criteria)\n",
    "    \n",
    "    return pd.DataFrame({ 'Altura Máxima' : evaluatedDepths,\n",
    "                          'Criterio de evaluación de corte' : evaluatedCriterias,\n",
    "                          'Accuracy (training)' : trainingResults,\n",
    "                          'Accuracy (validación)' : validationResults}).sort_values(by=['Criterio de evaluación de corte'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla con combinaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura Máxima</th>\n",
       "      <th>Criterio de evaluación de corte</th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.820090</td>\n",
       "      <td>0.652829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.928154</td>\n",
       "      <td>0.650320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infinito</td>\n",
       "      <td>gini</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.668685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.791947</td>\n",
       "      <td>0.682955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.917243</td>\n",
       "      <td>0.694554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Infinito</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura Máxima Criterio de evaluación de corte  Accuracy (training)  \\\n",
       "0             3                            gini             0.820090   \n",
       "2             5                            gini             0.928154   \n",
       "4      Infinito                            gini             1.000000   \n",
       "1             3                         entropy             0.791947   \n",
       "3             5                         entropy             0.917243   \n",
       "5      Infinito                         entropy             1.000000   \n",
       "\n",
       "   Accuracy (validación)  \n",
       "0               0.652829  \n",
       "2               0.650320  \n",
       "4               0.668685  \n",
       "1               0.682955  \n",
       "3               0.694554  \n",
       "5               0.682952  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(segundaTablaEjercicio2(DecisionTreeClassifier))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Extra: Resultados para nuestro clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(primerTablaEjercicio2(ourTree.MiClasificadorArbol))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(segundaTablaEjercicio2(ourTree.MiClasificadorArbol))\n",
    "#esta tabla tardo 10 minutos en crearse, ver como mejorar performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score = make_scorer(roc_auc_score)\n",
    "n_iter_search = 70\n",
    "def performGridSearch(clasiffier, param_grid):\n",
    "    start = time()\n",
    "    gridSearch = GridSearchCV(clasiffier, param_grid, cv=kfold, scoring=roc_auc_score, return_train_score=False)\n",
    "    gridSearch.fit(X_desarrollo, y_desarrollo)\n",
    "    return {\"bestScore\" : gridSearch.best_score_, \"bestParams\" : gridSearch.best_params_, \"executionTime\" : time() - start, \"allScores\" : gridSearch.cv_results_}\n",
    "\n",
    "def performRandomSearch(classifier, param_dist):\n",
    "    start = time()\n",
    "    randomSearch = RandomizedSearchCV(classifier, param_distributions=param_dist, n_iter=n_iter_search, cv=kfold, scoring=roc_auc_score, refit=True)\n",
    "    randomSearch.fit(X_desarrollo, y_desarrollo)\n",
    "    return {\"bestScore\" : randomSearch.best_score_, \"bestParams\" : randomSearch.best_params_, \"executionTime\" : time() - start}\n",
    "\n",
    "\n",
    "def displayBestParamsTable(classifier, paramsGridSearch, paramsRandomSearch):\n",
    "    gridSearchResult = performGridSearch(classifier, paramsGridSearch);\n",
    "    randomSearchResult = performRandomSearch(classifier, paramsRandomSearch);\n",
    "    df =  pd.DataFrame({ ' ' : [\"Mejor performance (Roc Auc)\"],\n",
    "                          'Grid Search' : [gridSearchResult[\"bestScore\"]],\n",
    "                          'Random Search' : [randomSearchResult[\"bestScore\"]]\n",
    "                        })      \n",
    "    display(df.set_index(' '))\n",
    "    orderedBestGridParams = collections.OrderedDict(sorted(gridSearchResult[\"bestParams\"].items()))\n",
    "    orderedBestRandomParams = collections.OrderedDict(sorted(randomSearchResult[\"bestParams\"].items()))\n",
    "    display(pd.DataFrame({ 'Mejores parámetros Grid Search' : list(orderedBestGridParams.keys()),\n",
    "                          '' : list(orderedBestGridParams.values())\n",
    "                        }).set_index('Mejores parámetros Grid Search'))\n",
    "    display(pd.DataFrame({ 'Mejores parámetros Random Search' : list(orderedBestRandomParams.keys()),\n",
    "                          '' : list(orderedBestRandomParams.values())\n",
    "                        }).set_index('Mejores parámetros Random Search'))\n",
    "    \n",
    "    allScores = renameAndDeleteColumnsInAllScoresTable(gridSearchResult[\"allScores\"])\n",
    "    \n",
    "    display(HTML('<h6 style=\"font-style:/\"/\";font-size:/\"88%/\"\">Todos los resultados del grid search (ordenados por performance):</h6>'))\n",
    "    \n",
    "    display(pd.DataFrame(allScores).sort_values(by=['']).set_index(\"\"))\n",
    "    \n",
    "def renameAndDeleteColumnsInAllScoresTable(allScores):\n",
    "    allScores.pop('mean_fit_time', None)\n",
    "    allScores.pop('std_fit_time', None)\n",
    "    allScores.pop('std_score_time', None)\n",
    "    allScores.pop('params', None)\n",
    "    allScores.pop('split0_test_score', None)\n",
    "    allScores.pop('split1_test_score', None)\n",
    "    allScores.pop('split2_test_score', None)\n",
    "    allScores.pop('split3_test_score', None)\n",
    "    allScores.pop('split4_test_score', None)\n",
    "    allScores.pop('mean_score_time', None)\n",
    "    allScores.pop('std_test_score', None)\n",
    "    newDict = {}\n",
    "    for key in list(allScores.keys()):\n",
    "        if key.startswith(\"param_\"):\n",
    "            newDict[key[6:]] = allScores.pop(key);\n",
    "    \n",
    "    for key in list(newDict.keys()):\n",
    "        allScores[key]=newDict[key]\n",
    "    \n",
    "    allScores['Roc Auc'] = allScores.pop(\"mean_test_score\");\n",
    "    allScores[''] = allScores.pop(\"rank_test_score\");\n",
    "    \n",
    "    \n",
    "    return allScores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grid Search</th>\n",
       "      <th>Random Search</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mejor performance (Roc Auc)</th>\n",
       "      <td>0.75703</td>\n",
       "      <td>0.766294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Grid Search  Random Search\n",
       "                                                       \n",
       "Mejor performance (Roc Auc)      0.75703       0.766294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mejores parámetros Grid Search</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shrinkage</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solver</th>\n",
       "      <td>lsqr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    \n",
       "Mejores parámetros Grid Search      \n",
       "shrinkage                        0.6\n",
       "solver                          lsqr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mejores parámetros Random Search</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shrinkage</th>\n",
       "      <td>0.54342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solver</th>\n",
       "      <td>lsqr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         \n",
       "Mejores parámetros Random Search         \n",
       "shrinkage                         0.54342\n",
       "solver                               lsqr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h6 style=\"font-style:/\"/\";font-size:/\"88%/\"\">Todos los resultados del grid search (ordenados por performance):</h6>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shrinkage</th>\n",
       "      <th>solver</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.757030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.756726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.751551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.746944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.742867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.731441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.724064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.699589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.679914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.650884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shrinkage solver   Roc Auc\n",
       "                             \n",
       "1        0.6   lsqr  0.757030\n",
       "2        0.7   lsqr  0.756726\n",
       "3        0.5   lsqr  0.751551\n",
       "4        0.4   lsqr  0.746944\n",
       "5        0.8   lsqr  0.742867\n",
       "6        0.9   lsqr  0.731441\n",
       "7        0.3   lsqr  0.724064\n",
       "8        0.2   lsqr  0.699589\n",
       "9        0.1   lsqr  0.679914\n",
       "10         0   lsqr  0.650884"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda_param_grid = [{'solver': ['lsqr'], 'shrinkage': np.arange(0, 1, 0.1)}]\n",
    "\n",
    "lda_param_random = {'solver': ['lsqr'], 'shrinkage': np.arange(0, 1, 0.000001)}\n",
    "\n",
    "displayBestParamsTable(LinearDiscriminantAnalysis(),lda_param_grid, lda_param_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de LDA intenta partir el espacio de X en dos, defininedo con un hiperplano cuáles son las instancias\n",
    "que pertenecen a una clase u otra. Este algoritmo funciona bien cuando cada una de las clases tiene una distribución normal y además se encuentran bien separadas. En el caso donde X es una matriz con múltiples columnas, el algoritmo asume que cada columna sigue una distribucion gaussiana de una dimensión, con alguna correlacion entre cada par de columnas. Esta correlacion se refleja en una matriz de co-varianzas, la cual es utilizada por el algoritmo. La matriz de co-varianza se calcula en base a las muestras, pero en la realidad es desconocida.\n",
    "Skelarn provee distintos hiper parámetros para LDA. Nostros exploramos sobre Shrinkage y el solver lo dejamos fijo en 'lsqr'.\n",
    "\n",
    "Solver: Según la documentación el solver por default es \"svd\", el cual no utiliza la matriz de covarianza, pero dado que la documentación no explica qué utiliza en vez, descartamos al solver \"svd\", teniendo en cuenta que además el algoritmo de LDA, tal cual se lo menciona en la bibliografía de la materia, utiliza una matriz de covarianza.\n",
    "Al setear el solver en 'lsqr', el valor de shrinkage es tenido en cuenta, el cual puede tomar un valor entre 0 y 1; donde 0 significa computar la matriz de co-varianza empiricamente (con los datos de la muestra), y donde 1 significa utilizar en vez una matriz diagonal que contiene la varianza de cada feature. Los valores intermedios corresponden a diferentes convinaciones lineales de ambas matrices. Si se usa el valor 'auto' para este parametro el valor de shrinkage se determina analiticamente segun el lema de Ledoit-Wolf el cual representa un mejor estimador de la matriz de covarianza real cuando la cantidad de features es muy grande (\"http://scikit-learn.org/stable/modules/lda_qda.html#lda-qda\").\n",
    "Teniendo en cuenta que la cantidad de features es 200, un número relativamente grande respecto de la cantidad de instancias que es 435 podemos decir que las condiciones son compatibles con la implementacion de shrinkage. Esto coincide con nuestros resultados, dado que nuestro mejor resultado fue para un shrinkage de 0.6 y representa a una matriz \"interemedia\" entre la matriz de co-varianza empírica y la matriz diagonal de varianzas. Si contaramos con un mayor numero de instancias o un menor numero de features la matriz de covarianza empirica seria una buea estimacion de la real y podria esperarse que el grid search arroje un valor mas cercano a 0.\n",
    "En cuanto al random search, variamos el valor de shrinkage entre 0 y 1  con un step de 0.000001. El algoritmo de Random Search encontró el mejor resultado con shrinkage en 0.568393, obteniendo un resultado de Roc Auc en 0.763814, mejor que el obenido en Grid Search.\n",
    "Como conclusión general, dado que la performance no pudo superar un Roc Auc de 0.76, podemos decir que el algoritmo no puede encontrar un hiperplano que divida muy bien las dos clases. Es decir que podemos conjeturar que las features no siguen distribuciones normales multivariantes con las clases bien separadas entre sí.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbol de Decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_param_grid = [{'max_depth': [3,5,10,15,20,40,None],'criterion': ('gini','entropy') }]\n",
    "\n",
    "tree_param_random = {'max_depth':np.append(np.arange(1, 41), None),'criterion': ('gini','entropy') }\n",
    "\n",
    "displayBestParamsTable(DecisionTreeClassifier(),tree_param_grid, tree_param_random)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar a analizar los resultados arrojados para la performance del algoritmo de Arboles de Decisión es importante comentar que cada vez que corremos el script de esta notebook, el orden de los resultados  para cada combinación varía mucho de corrida en corrida. Esto es por el fuerte componente aleatorio del algoritmo, relacionado con el hecho de que ante dos o más pares de (atributo / valor) que midan igual en ganancia de informacion o en ganancia gini, el algoritmo se quedará con alguno de ellos al azar. Aclaradndo además que en ninguna se alcanzo una performance superior al 0.70, explicamos los resultados arrojados para esta corrida.\n",
    "Notamos que en este caso el criterio de entropía dio siempre mejor que el de gini. De todas maneras los criterios son muy similares y se suele usar gini por el hecho de que es más rapido para computar dado que no tiene función logaritmo.\n",
    "En este caso el mejor de entropía dio 0.69 mientras que el mejor de gini dio 0.67. En otras corridas gini dio mejor que entropía.\n",
    "Con respecto a las alturas, podemos ver que la performance no fue muy buena para ninguna de ellas. Una razon podría ser que para alturas altas el algoritmo tiende al overfitting, es decir anda bien cuando se testea con los datos de training pero no con los de validación. Por el otro lado con las alturas bajas, el algoritmo no logra generalizar, pues tiene en cuenta demasiado pocos atributos y descarta muchos que a la hora de la validación le terminan jugando en contra.\n",
    "En este caso la mejor performance fue para altura en 20, pero para otras corridas la mejor performance fue para 5, 15, etc.\n",
    "Cabe destacar que este es un algoritmo goloso, en el sentido que puede estar tomando decisiones malas, desde el punto de vista que pueden ser buenas decisiones en el contexto puntual en el que se toma la decisión pero malas desde un contexto global. \n",
    "El random search en este caso encontró una performance levemente superior del 0.70."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_param_grid = {'n_neighbors': [1,5, 30, 50, 100], 'p' : [1,2], \"weights\" : ['uniform', 'distance']}\n",
    "KNN_param_random = {'n_neighbors': np.arange(1, 101), 'p' : [1,2], \"weights\" : ['uniform', 'distance']}\n",
    "displayBestParamsTable(KNeighborsClassifier(),KNN_param_grid, KNN_param_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo se basa en predecir la clase de una nueva instancia en base a las clases de sus \"vecinos\". Para esto, el algoritmo provee hiperparámetros como la cantidad de vecinos a tomar en cuenta, o \"weights\" que al setearlo en \"distance\" le da mayor importancia a los vecinos más cercanos y menor a los más lejanos, mientras que al setearlo en \"uniform\" le da igual importancia a todos. El parámetro \"p\" define el tipo de distancia, donde p define la norma p a ser tenida en cuenta. Nosotros exploramos con p en 1 y 2.\n",
    "Para el valor de n buscamos en 1, 5, 30 50 y 100. Nuestro mejor resultado fue con n en 30, p en 2 y weights en \"distance\".\n",
    "Notar que el hiperparámetro que mayor influyó en los resultados fue el del n, con resultados entre 0.72 y 0.75 para enes en 30, 50 y 100, y con los peores resultados para enes chicos; de 0.67 para n en 5, y en 0.60-0.61 para n en 1.\n",
    "Notar que para un mismo n, variar el p o variar el weight no proporcionó mayores diferencias. La mayor diferencia fue de 0.21 parea el caso 11 en la tabla, que con un n en 30 dio un resultado de 0.729 que comparado al mejor caso, con n también en 30, dio 0.21 menos de Roc Auc. \n",
    "Podríamos pensar que para enes chicos el algoritmo funciona mal porque no logra generalizar y se pega demasiado a los valores del set de training. Es decir tiende al overfitting. Para distancias grandes funciona mejor, logrando una mejor generalización, aunque tampoco puede llegar a demasiados buenos resultados. Posiblemente no existe un ene fijo que pueda generalizar del todo bien para este set de datos, es decir, dependiendo de la instancia es posible que la cantidad de vecinos que mejor define la clase de la nueva instancia sea un ene diferente. Evidentemente para muchos casos, sucedió que la clase de la instancia nueva no era la de la mayoría de sus ene vecinos más cercanos, sino la contaria.\n",
    "En esta corrida, no logramos obtener mejores resultados con el Random Search, obteniendo una performance de 0.74722, con n en 61, p en 2 y weights en distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_param_grid = [{'kernel': ['rbf'], 'gamma': [1000,100,10,1,1e-1,1e-2,1e-3, 1e-4, 1e-5,1e-6,1e-7,1e-8,1e-9],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100,1000]}]\n",
    "SVM_param_random = {'kernel': ['rbf'], 'gamma':sp.stats.expon(scale=.1),\n",
    "                     'C': sp.stats.expon(scale=100)}\n",
    "displayBestParamsTable(SVC(),SVM_param_grid, SVM_param_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El clasificador SVM, en el modo lineal, intenta separar las instancias en el espacio de X por medio de un hiperplano. En el modo no lineal, el algoritmo proyecta nuevas dimensiones como función de las dimensiones existentes, e intenta generar un hiperplano en este nuevo espacio.\n",
    "El nombre del clasificador Support Vector Machines, hace referencia al hecho de que el algoritmo se basa unos vectores soporte que definen un margen que separará las dos clases. Para encontrar estos vectores, el algoritmo necesita de unas pocas instancias, las más cercanas a estos posibles vectores, mientras que el resto de las instancias no influyen en los mismos.\n",
    "De esta manera intenta separar las clases, con un margen en el medio, siendo este margen más ancho o más angosto dependiendo del parámetro C. Este parámetro define de modo inverso cuanto error el algoritmo está dispuesto a aceptar, en el sentido de cuantas instancias pueden caer dentro del margen. Si el valor de C es grande, esto quiere decir que aceptamos poco error, y que entonces el margen es chico, de manera que pocas instancias caigan ahi dentro. De manera contraria si el valor de C es chico entonces toleramos más error.\n",
    "Cuando resulta imposible encontrar un margen en el espacio de X que separe bien las instancias, se puede utilizar otro tipo de kernel, no lineal, que de manera implícita simula un espacio de mayores dimensiones. En nuestro caso exploramos con el kernel rbf, además del lineal.\n",
    "Cuando utilizamos el kernel rbf, este se puede combinar con un nuevo hiperparámetro gamma. El gamma define de manera intuitiva cuán lejos alcanza la influencia de una instancia de training particular, con valores pequeños significando un alcance lejano y con valores grandes significando que el alcance es corto.\n",
    "Si el gamma es demasiado grande, cada instancia de trainign define por si misma, junto con una pequeña distancia alrededor, que se area corresponde a la clase de ese punto, sería algo similar a definir KNN con cantidad de vecinos en uno, con altos riesgos de overfitting. En cambio, si el gamma es demasido chico, el modelo no podrá capturar la forma de los datos e intentará hacer una separación similar a la lineal.\n",
    "En nuestro Grid Search exploramos para el kernel de rbf los gammas en [1000,100,10,1,1e-1,1e-2,1e-3, 1e-4, 1e-5,1e-6,1e-7,1e-8,1e-9]. Mientras que el C lo variamos en 1, 10, 100 y 1000.\n",
    "Vemos en nuestro caso que todas las pruebas con gamma mayores o iguales que 1e-1 dieron una performance de 0.5, al igual que todos los resultados para gamams menores o iguales que 1e-8. De esta forma, los mejores gammas se encontraron en un rango intermedio entre 1e-2 y 1e-6, siendo la mejor peformance de 0.75 para gamam en 1e-05 y C en 100.\n",
    "Notar que en el caso del Kernel linal, el mejor resultado fue de 0.68, esto indica que el algoritmo, restringido a las dimensiones de X, no pudo encontrar una buena forma de separar las clases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcion\n",
    "\n",
    "### Sepresentan en las tablas los mejores resultados segun score usando la metrica ROC_AUC  para cada clasificador y la correspondiente combinacion de hiperparametros. \n",
    "\n",
    "### para todos los clasificadores el score obtenido estuvo entre $0.7$ y $0.76$, una conjetura inicial fue la falta de entrenamiento para lo que ensayamos mas folds, para que el entrenamiento parcial a la hora de sacar un score contenga un conjunto de datos mayor, esto no cambio significativamente los valores. Luego se penso es el preproceso de datos y se probo con la normalizacion y escalamiento de los valores de las instancias, esto nuevamente no condujo a mejoras en las predicciones. Por último, dada la coincidencia de score para diferentes clasificadores , se penso en que el factor limitante sea la falta de datos o mas probablemente la eleccion de atributos.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
